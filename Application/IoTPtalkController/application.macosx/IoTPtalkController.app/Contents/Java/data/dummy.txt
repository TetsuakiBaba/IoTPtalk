文字起こしツールとしてIPTalkはまさしくデファクトスタンダードとして国内においては広く認知されています。
技術の発達によって自動文字起こしもかなりの精度まだ向上しましたが、
依然として人間の手直しや人力による字幕精度には及ばないのが現状です。
例えば情報処理学会アクセシビリティ研究会において、
juliusによる自動字幕（Thanks for 秋田先生）、
UDTalkによる自動字幕サービスを取り入れていますが、
いずれも最終的には人間の手直しをした上で字幕作成を行っています。
IPTalk開発者の栗田 茂明氏によってこのIPTalkが誕生してから2019年9月現在で、
20年が経過しています。大学内のダイバーシティ推進では学生による字幕保障としてIPTalkをみることがよくありますし、
大きな会議においても主導字幕ではIPTalkが本当によく利用されています。
IPtalk開発の歴史は https://www.jstage.jst.go.jp/article/johokanri/59/6/59_366/_pdf を参照してください。
ユーザの様々な要望に答える形で、
IPTalkには非常に多くの機能が含まれています。
例えば会場内の字幕文字が小さくて見えない、
なんて場合は、
IPTalkのローカルネットhttp機能を使えばブラウザを通じて文字通訳を手元のスマートフォン等で閲覧することができます。
また、カメラ画像に字幕を表示する、なんてこともIPTalkの機能で利用できます。
一方でこれを学会のインターネット配信側から技術的観点で見直してみると、
必ずしもインターネット中継配信用途に最適化されているとは言えない状況です。
（もちろん、それを想定して機能追加していないので当然ではありますが）何から何まで栗田氏におんぶにだっこではいけない、
と思い。
アクセシビリティ研究会10回分の知見から、インターネット中継に適切にIPTalkの字幕を入れるために必要な環境を開発することにしました。
以下、参考までにアクセシビリティ研究会最初のころは、字幕保障を中継にいれるために画像をそのままキャプチャしていました。
下記のような構成図となり、多くの機材が必要となることがわかります。